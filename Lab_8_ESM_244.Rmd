---
title: "Lab 8 ESM 244"
author: "Kristen Peach"
date: "3/7/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Load Packages

```{r load_packages}


library(ggplot2) 
library(readr) 
library(dplyr)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(maptools)
library(corrplot)


```

###Column graph of Texas oil spills

```{r}


oil_spills <- read_csv("oil_spills.csv")

df <- oil_spills %>% 
  filter(`Accident State` == "TX" & `Accident Year` < 2017) %>% 
  group_by(`Accident Year`) %>% 
  summarise(Loss = sum(`Net Loss (Barrels)`))

 #if you ever fail to change the column headings to R friendly names you just have to add these '' to surround column headings (under squiggly tilde on keyboard, uppermost left key)

# we want to calculate the net loss of oil in Texas by year so we need to group by year

# now the df data frame is a super simplified data set with just the year and the net loss of oil from that year

colnames(df) <- c("Year", "Loss")

#renamed column headings for simplified data set 

ggplot(df, aes(x= Year, y= Loss)) +
  geom_col()

#create a column graph of this simple data set 

```

**When I see things in the Git window on the right it means I have changed things in the project locally that I have NOT pushed to Github yet. Right now these changes only exist locally**


### Leaflet plot of spill locations in TX in 2016

```{r}

df_loc <- oil_spills %>% 
  filter(`Accident State` == "TX" & `Accident Year` == 2016) %>% 
  select(Latitude, Longitude, `Net Loss (Barrels)`)

#making new data frame for Texas oil spills in 2016

colnames(df_loc) <- c("latitude", "longitude", "net_loss")

#changing the column names to R friendly names

# Now we have to tell it that this is spatial information

oil_sf <- st_as_sf(df_loc, coords = c("longitude", "latitude"), crs = 4326)

#remember longitude always has to be before latitude or you will get a flipped graph. Now if you look at the class of oil_sf is sf

#class(oil_sf)

leaflet(oil_sf) %>% 
  addTiles() %>% 
  addMarkers()

```

## Make a tmap plot with the Texas state shapefile

```{r}

states <- st_read(dsn = ".", layer = "states")

tex_border <- states %>% 
  filter(STATE_NAME == "Texas") %>% 
  st_transform(4326)

#now we have data that matches the coordinate system of the oil spill data we have

plot(tex_border)

#there are 5 non geometry columns so it shows 5 texases 

tm_shape(tex_border) +
  tm_polygons() +
  tm_shape(oil_sf) +
  tm_dots(size = 0.3)

#are these random locations? This question doesnt really make sense for this data set because obviously there are more oil spills where there are more oil pipelines but for the sake of connecting lecture material...

```

###Convert the data to spatial points patterns (combination of point data and the bounding window)

```{r}

#Now were gonna convert from simple features back to spatial data frame data. The second line is telling R this is spatial data that we want to use spatial point pattern analysis on

spill_sp <- as(oil_sf, "Spatial")

spill_ppp <- as(spill_sp, "ppp")

tx_sp <- as(tex_border, "Spatial")

tx_owin <- as(tx_sp, "owin")

all_ppp <- ppp(spill_ppp$x, spill_ppp$y, window = tx_owin)

#It rejected 4 points that were not within the polygon window. There were a few points or "events" that were outside the borders of Texas

```

### A density plot:

```{r}

plot(density(all_ppp, sigma = 0.4))

#this creates a density plot of the location of the oil spills



```

###Quadrat test for spatial evenness

```{r}

#?quadrat.test

oil_qt <- quadrat.test(all_ppp, nx = 5, ny = 5)

#this takes the whole state of texas and breaks it into 5 regions in each direction. Count the number of events in each quadrat, gets the frequency of events for each quadrat

oil_qt

#we see a very very small p value. The null hypothesis is complete spatial randomness. We would reject the null hypothesis. We would retain the alternative that the data is not evenly spatially distributed.  If you look at the points on the map of Texas the points don't appear to be spatially random (confirms test). 

plot(all_ppp)
plot(oil_qt, add = TRUE, cex = 0.5)

#for partial quadrats it figures out what the frequency of events "should" be if spatial evenness was true. Complete quadrats the expected frequency (if data was evenly distributed) is 14.5.

```

###G-Function for Nearest Neighbor Analysis

```{r}

lag <- seq(0,1, by = 0.01)

oil_gfun <- envelope(all_ppp, fun = Gest, r = lag, nsim = 100)

#oil_gfun

ggplot(oil_gfun, aes(x= lag, y = obs)) +
  geom_line(color = "black") +
  geom_line(aes(x= lag, y = theo), color = "red")


```

###Nearest neighbor using the L-function (Ripley's K, standardized)

```{r}

r2 <- seq(0,3, by = 0.5)

oil_lfun <- envelope(all_ppp, fun = Lest, r = r2, nsim = 20, global = TRUE)

ggplot(oil_lfun, aes(x= r2, y = obs)) +
  geom_line(color = "black") +
  geom_line(aes(x = r2, y = theo), color = "blue")

#Takeway message is the same. There are still more close neighbors in this spatial data than we would expect if total spatial randomness (really evenness) was true 



```













