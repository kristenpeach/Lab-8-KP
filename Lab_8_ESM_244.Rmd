---
title: "Lab 8 ESM 244"
author: "Kristen Peach"
date: "3/7/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Load Packages

```{r load_packages}


library(ggplot2) 
library(readr) 
library(dplyr)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(maptools)
library(corrplot)


```

###Column graph of Texas oil spills

```{r}


oil_spills <- read_csv("oil_spills.csv")

df <- oil_spills %>% 
  filter(`Accident State` == "TX" & `Accident Year` < 2017) %>% 
  group_by(`Accident Year`) %>% 
  summarise(Loss = sum(`Net Loss (Barrels)`))

 #if you ever fail to change the column headings to R friendly names you just have to add these '' to surround column headings (under squiggly tilde on keyboard, uppermost left key)

# we want to calculate the net loss of oil in Texas by year so we need to group by year

# now the df data frame is a super simplified data set with just the year and the net loss of oil from that year

colnames(df) <- c("Year", "Loss")

#renamed column headings for simplified data set 

ggplot(df, aes(x= Year, y= Loss)) +
  geom_col()

#create a column graph of this simple data set 

```

**When I see things in the Git window on the right it means I have changed things in the project locally that I have NOT pushed to Github yet. Right now these changes only exist locally**


### Leaflet plot of spill locations in TX in 2016

```{r}

df_loc <- oil_spills %>% 
  filter(`Accident State` == "TX" & `Accident Year` == 2016) %>% 
  select(Latitude, Longitude, `Net Loss (Barrels)`)

#making new data frame for Texas oil spills in 2016

colnames(df_loc) <- c("latitude", "longitude", "net_loss")

#changing the column names to R friendly names

# Now we have to tell it that this is spatial information

oil_sf <- st_as_sf(df_loc, coords = c("longitude", "latitude"), crs = 4326)

#remember longitude always has to be before latitude or you will get a flipped graph. Now if you look at the class of oil_sf is sf

#class(oil_sf)

leaflet(oil_sf) %>% 
  addTiles() %>% 
  addMarkers()

```

## Make a tmap plot with the Texas state shapefile

```{r}

states <- st_read(dsn = ".", layer = "states")

tex_border <- states %>% 
  filter(STATE_NAME == "Texas") %>% 
  st_transform(4326)

#now we have data that matches the coordinate system of the oil spill data we have

plot(tex_border)

#there are 5 non geometry columns so it shows 5 texases 

tm_shape(tex_border) +
  tm_polygons() +
  tm_shape(oil_sf) +
  tm_dots(size = 0.3)

#are these random locations? This question doesnt really make sense for this data set because obviously there are more oil spills where there are more oil pipelines but for the sake of connecting lecture material...

```

###Convert the data to spatial points patterns (combination of point data and the bounding window)

```{r}

#Now were gonna convert from simple features back to spatial data frame data. The second line is telling R this is spatial data that we want to use spatial point pattern analysis on

spill_sp <- as(oil_sf, "Spatial")

spill_ppp <- as(spill_sp, "ppp")

tx_sp <- as(tex_border, "Spatial")

tx_owin <- as(tx_sp, "owin")

all_ppp <- ppp(spill_ppp$x, spill_ppp$y, window = tx_owin)

#It rejected 4 points that were not within the polygon window. There were a few points or "events" that were outside the borders of Texas

```
















